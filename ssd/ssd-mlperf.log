_CUDA_COMPAT_STATUS=CUDA Driver UNAVAILABLE (cuInit(0) returned 100)
NVIDIA_PYTORCH_VERSION=19.05
MOFED_VERSION=4.4-1.0.0
COCOAPI_VERSION=2.0+nv0.3.1
CUDNN_VERSION=7.6.0.64
HOSTNAME=ssd
DATADIR=/var/home/core/data/u1/mlperf/dataset/single_stage_detector
NVIDIA_REQUIRE_CUDA=cuda>=5.0
KUBERNETES_PORT=tcp://172.30.0.1:443
KUBERNETES_PORT_443_TCP_PORT=443
TERM=xterm
NSIGHT_SYSTEMS_VERSION=2019.3.1
CUBLAS_VERSION=10.2.0.163
LIBRARY_PATH=/usr/local/cuda/lib64/stubs:
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_HOST=172.30.0.1
NEXP=1
LC_ALL=C.UTF-8
PYTHONIOENCODING=utf-8
LD_LIBRARY_PATH=/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
NVIDIA_VISIBLE_DEVICES=all
ENV=/etc/shinit
_CUDA_COMPAT_PATH=/usr/local/cuda/compat
CUDA_CACHE_DISABLE=1
NVIDIA_DRIVER_CAPABILITIES=compute,utility
TRT_VERSION=5.1.5.0
CUDA_DRIVER_VERSION=418.67
NVIDIA_BUILD_ID=6411784
PATH=/opt/conda/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PWD=/workspace/single_stage_detector
PYTORCH_VERSION=1.1.0a0+828a6a3
PYTORCH_BUILD_VERSION=1.1.0a0+828a6a3
CUDA_VERSION=10.1.163
OMPI_MCA_btl_vader_single_copy_mechanism=none
SHLVL=1
HOME=/root
DALI_VERSION=0.9.1
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_SERVICE_PORT_HTTPS=443
DALI_BUILD=719215
OPENMPI_VERSION=3.1.3
NCCL_VERSION=2.4.6
INSLURM=0
BASH_ENV=/etc/bash.bashrc
LOGDIR=/home/mlperf/logs
OPENCV_FOR_THREADS_NUM=1
OMP_NUM_THREADS=1
PYTORCH_BUILD_NUMBER=0
KUBERNETES_PORT_443_TCP_ADDR=172.30.0.1
KUBERNETES_PORT_443_TCP=tcp://172.30.0.1:443
_=/usr/bin/printenv
Run vars: id 18338 gpus 4 mparams 
STARTING TIMING RUN AT 2020-04-13 05:46:42 AM
+ NUMEPOCHS=80
running benchmark
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python3 -m bind_launch --nsockets_per_node 2 --ncores_per_socket 16 --nproc_per_node 4 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 120 --eval-batch-size 160 --warmup 650 --lr 2.92e-3 --wd 1.6e-4 --use-nvjpeg --use-roi-decode
:::MLL 1586756803.125 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1586756803.125 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1586756803.125 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
:::MLL 1586756803.128 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
0 Using seed = 2008000344
2 Using seed = 2008000346
3 Using seed = 2008000347
1 Using seed = 2008000345
:::MLL 1586756809.559 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1586756810.065 model_bn_span: {"value": 120, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1586756810.065 global_batch_size: {"value": 480, "metadata": {"file": "train.py", "lineno": 481}}
:::MLL 1586756810.070 opt_base_learning_rate: {"value": 0.045, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1586756810.070 opt_weight_decay: {"value": 0.00016, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1586756810.070 opt_learning_rate_warmup_steps: {"value": 650, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1586756810.070 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
epoch nbatch loss
:::MLL 1586756814.420 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1586756814.421 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.46s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.53s)
creating index...
time_check a: 1586756816.132649660
time_check b: 1586756820.143927097
:::MLL 1586756820.805 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1586756820.807 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.529, Average Loss: 0.023, avg. samples / sec: 43.60
Iteration:     20, Loss function: 20.762, Average Loss: 0.446, avg. samples / sec: 1933.15
Iteration:     40, Loss function: 20.231, Average Loss: 0.844, avg. samples / sec: 2111.74
Iteration:     60, Loss function: 15.288, Average Loss: 1.195, avg. samples / sec: 2167.91
Iteration:     80, Loss function: 11.352, Average Loss: 1.418, avg. samples / sec: 2163.25
Iteration:    100, Loss function: 10.030, Average Loss: 1.592, avg. samples / sec: 2144.77
Iteration:    120, Loss function: 9.206, Average Loss: 1.746, avg. samples / sec: 2165.30
Iteration:    140, Loss function: 8.721, Average Loss: 1.890, avg. samples / sec: 2157.22
Iteration:    160, Loss function: 8.904, Average Loss: 2.029, avg. samples / sec: 2159.97
Iteration:    180, Loss function: 8.673, Average Loss: 2.161, avg. samples / sec: 2157.74
Iteration:    200, Loss function: 8.567, Average Loss: 2.286, avg. samples / sec: 2160.83
Iteration:    220, Loss function: 8.203, Average Loss: 2.405, avg. samples / sec: 2167.89
Iteration:    240, Loss function: 8.238, Average Loss: 2.521, avg. samples / sec: 2158.06
:::MLL 1586756876.533 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1586756876.533 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:    260, Loss function: 7.604, Average Loss: 2.629, avg. samples / sec: 2148.91
Iteration:    280, Loss function: 7.411, Average Loss: 2.728, avg. samples / sec: 2147.18
Iteration:    300, Loss function: 8.056, Average Loss: 2.833, avg. samples / sec: 2153.32
Iteration:    320, Loss function: 7.486, Average Loss: 2.933, avg. samples / sec: 2150.34
Iteration:    340, Loss function: 7.256, Average Loss: 3.022, avg. samples / sec: 2149.54
Iteration:    360, Loss function: 7.313, Average Loss: 3.110, avg. samples / sec: 2153.24
Iteration:    380, Loss function: 7.261, Average Loss: 3.191, avg. samples / sec: 2147.32
Iteration:    400, Loss function: 6.971, Average Loss: 3.270, avg. samples / sec: 2144.55
Iteration:    420, Loss function: 6.853, Average Loss: 3.345, avg. samples / sec: 2148.61
Iteration:    440, Loss function: 7.135, Average Loss: 3.418, avg. samples / sec: 2139.11
Iteration:    460, Loss function: 6.760, Average Loss: 3.490, avg. samples / sec: 2139.56
Iteration:    480, Loss function: 6.399, Average Loss: 3.555, avg. samples / sec: 2144.76
:::MLL 1586756931.078 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1586756931.078 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 6.853, Average Loss: 3.620, avg. samples / sec: 2144.35
Iteration:    520, Loss function: 6.571, Average Loss: 3.681, avg. samples / sec: 2150.94
Iteration:    540, Loss function: 6.891, Average Loss: 3.740, avg. samples / sec: 2141.57
Iteration:    560, Loss function: 6.579, Average Loss: 3.796, avg. samples / sec: 2143.66
Iteration:    580, Loss function: 6.318, Average Loss: 3.854, avg. samples / sec: 2136.27
Iteration:    600, Loss function: 6.107, Average Loss: 3.905, avg. samples / sec: 2124.90
Iteration:    620, Loss function: 6.579, Average Loss: 3.954, avg. samples / sec: 2138.68
Iteration:    640, Loss function: 6.507, Average Loss: 4.000, avg. samples / sec: 2142.95
Iteration:    660, Loss function: 6.026, Average Loss: 4.043, avg. samples / sec: 2144.88
Iteration:    680, Loss function: 6.175, Average Loss: 4.084, avg. samples / sec: 2150.00
Iteration:    700, Loss function: 5.980, Average Loss: 4.122, avg. samples / sec: 2145.13
Iteration:    720, Loss function: 6.162, Average Loss: 4.160, avg. samples / sec: 2151.34
:::MLL 1586756985.731 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1586756985.731 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    740, Loss function: 6.052, Average Loss: 4.196, avg. samples / sec: 2148.91
Iteration:    760, Loss function: 5.740, Average Loss: 4.229, avg. samples / sec: 2150.38
Iteration:    780, Loss function: 5.890, Average Loss: 4.260, avg. samples / sec: 2144.14
Iteration:    800, Loss function: 5.551, Average Loss: 4.288, avg. samples / sec: 2148.33
Iteration:    820, Loss function: 5.850, Average Loss: 4.316, avg. samples / sec: 2150.35
Iteration:    840, Loss function: 5.863, Average Loss: 4.349, avg. samples / sec: 2148.52
Iteration:    860, Loss function: 5.785, Average Loss: 4.375, avg. samples / sec: 2142.68
Iteration:    880, Loss function: 5.788, Average Loss: 4.399, avg. samples / sec: 2139.94
Iteration:    900, Loss function: 5.617, Average Loss: 4.423, avg. samples / sec: 2147.64
Iteration:    920, Loss function: 5.606, Average Loss: 4.445, avg. samples / sec: 2150.40
Iteration:    940, Loss function: 5.299, Average Loss: 4.466, avg. samples / sec: 2141.50
Iteration:    960, Loss function: 5.422, Average Loss: 4.487, avg. samples / sec: 2144.51
:::MLL 1586757040.532 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1586757040.533 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 5.465, Average Loss: 4.506, avg. samples / sec: 2139.17
Iteration:   1000, Loss function: 5.331, Average Loss: 4.523, avg. samples / sec: 2142.04
Iteration:   1020, Loss function: 5.451, Average Loss: 4.539, avg. samples / sec: 2145.58
Iteration:   1040, Loss function: 5.507, Average Loss: 4.558, avg. samples / sec: 2144.54
Iteration:   1060, Loss function: 5.166, Average Loss: 4.573, avg. samples / sec: 2135.93
Iteration:   1080, Loss function: 5.387, Average Loss: 4.588, avg. samples / sec: 2136.63
Iteration:   1100, Loss function: 5.452, Average Loss: 4.601, avg. samples / sec: 2139.87
Iteration:   1120, Loss function: 5.272, Average Loss: 4.613, avg. samples / sec: 2141.04
Iteration:   1140, Loss function: 5.171, Average Loss: 4.626, avg. samples / sec: 2137.22
Iteration:   1160, Loss function: 5.599, Average Loss: 4.638, avg. samples / sec: 2141.32
Iteration:   1180, Loss function: 5.142, Average Loss: 4.648, avg. samples / sec: 2141.51
Iteration:   1200, Loss function: 5.272, Average Loss: 4.659, avg. samples / sec: 2124.04
Iteration:   1220, Loss function: 5.028, Average Loss: 4.669, avg. samples / sec: 2140.87
:::MLL 1586757095.291 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1586757095.292 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:   1240, Loss function: 5.015, Average Loss: 4.679, avg. samples / sec: 2131.24
Iteration:   1260, Loss function: 4.989, Average Loss: 4.688, avg. samples / sec: 2142.90
Iteration:   1280, Loss function: 5.194, Average Loss: 4.697, avg. samples / sec: 2138.83
Iteration:   1300, Loss function: 5.021, Average Loss: 4.704, avg. samples / sec: 2143.87
Iteration:   1320, Loss function: 4.914, Average Loss: 4.711, avg. samples / sec: 2148.88
Iteration:   1340, Loss function: 5.253, Average Loss: 4.717, avg. samples / sec: 2148.32
Iteration:   1360, Loss function: 5.016, Average Loss: 4.723, avg. samples / sec: 2146.50
Iteration:   1380, Loss function: 4.925, Average Loss: 4.728, avg. samples / sec: 2135.86
Iteration:   1400, Loss function: 4.849, Average Loss: 4.735, avg. samples / sec: 2143.14
Iteration:   1420, Loss function: 5.051, Average Loss: 4.740, avg. samples / sec: 2149.54
Iteration:   1440, Loss function: 4.995, Average Loss: 4.745, avg. samples / sec: 2133.85
Iteration:   1460, Loss function: 4.814, Average Loss: 4.749, avg. samples / sec: 2143.63
:::MLL 1586757149.967 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1586757149.968 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.768, Average Loss: 4.752, avg. samples / sec: 2130.11
Iteration:   1500, Loss function: 5.083, Average Loss: 4.755, avg. samples / sec: 2144.10
Iteration:   1520, Loss function: 4.809, Average Loss: 4.756, avg. samples / sec: 2144.37
Iteration:   1540, Loss function: 4.731, Average Loss: 4.758, avg. samples / sec: 2136.76
Iteration:   1560, Loss function: 4.994, Average Loss: 4.761, avg. samples / sec: 2146.34
Iteration:   1580, Loss function: 4.727, Average Loss: 4.764, avg. samples / sec: 2146.07
Iteration:   1600, Loss function: 4.610, Average Loss: 4.765, avg. samples / sec: 2140.98
Iteration:   1620, Loss function: 4.645, Average Loss: 4.766, avg. samples / sec: 2137.38
Iteration:   1640, Loss function: 5.097, Average Loss: 4.768, avg. samples / sec: 2143.26
Iteration:   1660, Loss function: 4.764, Average Loss: 4.769, avg. samples / sec: 2145.10
Iteration:   1680, Loss function: 4.519, Average Loss: 4.770, avg. samples / sec: 2137.31
Iteration:   1700, Loss function: 4.881, Average Loss: 4.772, avg. samples / sec: 2132.72
:::MLL 1586757204.908 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1586757204.909 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:   1720, Loss function: 4.501, Average Loss: 4.772, avg. samples / sec: 2140.55
Iteration:   1740, Loss function: 4.771, Average Loss: 4.772, avg. samples / sec: 2139.50
Iteration:   1760, Loss function: 4.753, Average Loss: 4.771, avg. samples / sec: 2138.00
Iteration:   1780, Loss function: 4.743, Average Loss: 4.772, avg. samples / sec: 2140.39
Iteration:   1800, Loss function: 4.515, Average Loss: 4.772, avg. samples / sec: 2140.86
Iteration:   1820, Loss function: 5.025, Average Loss: 4.771, avg. samples / sec: 2129.77
Iteration:   1840, Loss function: 4.756, Average Loss: 4.771, avg. samples / sec: 2138.44
Iteration:   1860, Loss function: 4.493, Average Loss: 4.770, avg. samples / sec: 2135.84
Iteration:   1880, Loss function: 4.847, Average Loss: 4.769, avg. samples / sec: 2143.92
Iteration:   1900, Loss function: 4.944, Average Loss: 4.766, avg. samples / sec: 2147.27
Iteration:   1920, Loss function: 4.916, Average Loss: 4.765, avg. samples / sec: 2140.24
Iteration:   1940, Loss function: 4.769, Average Loss: 4.765, avg. samples / sec: 2138.20
:::MLL 1586757259.645 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1586757259.645 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.487, Average Loss: 4.761, avg. samples / sec: 2133.23
Iteration:   1980, Loss function: 4.614, Average Loss: 4.759, avg. samples / sec: 2139.58
Iteration:   2000, Loss function: 4.389, Average Loss: 4.756, avg. samples / sec: 2142.49
Iteration:   2020, Loss function: 4.850, Average Loss: 4.754, avg. samples / sec: 2139.79
Iteration:   2040, Loss function: 4.826, Average Loss: 4.751, avg. samples / sec: 2146.67
Iteration:   2060, Loss function: 4.685, Average Loss: 4.749, avg. samples / sec: 2136.36
Iteration:   2080, Loss function: 4.894, Average Loss: 4.747, avg. samples / sec: 2131.23
Iteration:   2100, Loss function: 4.666, Average Loss: 4.745, avg. samples / sec: 2145.12
Iteration:   2120, Loss function: 4.613, Average Loss: 4.743, avg. samples / sec: 2142.02
Iteration:   2140, Loss function: 4.497, Average Loss: 4.741, avg. samples / sec: 2142.97
Iteration:   2160, Loss function: 4.452, Average Loss: 4.738, avg. samples / sec: 2138.84
Iteration:   2180, Loss function: 4.920, Average Loss: 4.735, avg. samples / sec: 2144.28
:::MLL 1586757314.370 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1586757314.371 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:   2200, Loss function: 4.819, Average Loss: 4.734, avg. samples / sec: 2136.71
Iteration:   2220, Loss function: 4.259, Average Loss: 4.729, avg. samples / sec: 2148.98
Iteration:   2240, Loss function: 4.316, Average Loss: 4.724, avg. samples / sec: 2141.88
Iteration:   2260, Loss function: 4.515, Average Loss: 4.720, avg. samples / sec: 2129.77
Iteration:   2280, Loss function: 4.532, Average Loss: 4.716, avg. samples / sec: 2147.70
Iteration:   2300, Loss function: 4.554, Average Loss: 4.713, avg. samples / sec: 2145.66
Iteration:   2320, Loss function: 4.191, Average Loss: 4.710, avg. samples / sec: 2139.23
Iteration:   2340, Loss function: 4.221, Average Loss: 4.707, avg. samples / sec: 2142.96
Iteration:   2360, Loss function: 4.763, Average Loss: 4.705, avg. samples / sec: 2139.33
Iteration:   2380, Loss function: 4.574, Average Loss: 4.703, avg. samples / sec: 2139.36
Iteration:   2400, Loss function: 4.721, Average Loss: 4.701, avg. samples / sec: 2141.10
Iteration:   2420, Loss function: 4.727, Average Loss: 4.698, avg. samples / sec: 2139.97
Iteration:   2440, Loss function: 4.687, Average Loss: 4.693, avg. samples / sec: 2139.19
:::MLL 1586757369.308 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1586757369.308 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.097, Average Loss: 4.689, avg. samples / sec: 2140.26
Iteration:   2480, Loss function: 4.525, Average Loss: 4.684, avg. samples / sec: 2137.96
Iteration:   2500, Loss function: 4.244, Average Loss: 4.680, avg. samples / sec: 2139.90
Iteration:   2520, Loss function: 4.404, Average Loss: 4.676, avg. samples / sec: 2144.25
Iteration:   2540, Loss function: 4.591, Average Loss: 4.673, avg. samples / sec: 2137.86
Iteration:   2560, Loss function: 4.408, Average Loss: 4.669, avg. samples / sec: 2143.95
Iteration:   2580, Loss function: 4.475, Average Loss: 4.665, avg. samples / sec: 2140.19
Iteration:   2600, Loss function: 4.368, Average Loss: 4.661, avg. samples / sec: 2142.35
Iteration:   2620, Loss function: 4.563, Average Loss: 4.657, avg. samples / sec: 2137.03
Iteration:   2640, Loss function: 4.389, Average Loss: 4.652, avg. samples / sec: 2139.15
Iteration:   2660, Loss function: 4.428, Average Loss: 4.648, avg. samples / sec: 2140.19
Iteration:   2680, Loss function: 4.405, Average Loss: 4.645, avg. samples / sec: 2140.83
:::MLL 1586757424.035 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1586757424.036 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:   2700, Loss function: 4.405, Average Loss: 4.640, avg. samples / sec: 2126.12
Iteration:   2720, Loss function: 4.370, Average Loss: 4.636, avg. samples / sec: 2136.90
Iteration:   2740, Loss function: 4.719, Average Loss: 4.631, avg. samples / sec: 2136.53
Iteration:   2760, Loss function: 4.428, Average Loss: 4.628, avg. samples / sec: 2140.58
Iteration:   2780, Loss function: 4.443, Average Loss: 4.623, avg. samples / sec: 2134.10
Iteration:   2800, Loss function: 4.329, Average Loss: 4.618, avg. samples / sec: 2140.70
Iteration:   2820, Loss function: 4.663, Average Loss: 4.613, avg. samples / sec: 2140.34
Iteration:   2840, Loss function: 4.303, Average Loss: 4.608, avg. samples / sec: 2144.05
Iteration:   2860, Loss function: 4.849, Average Loss: 4.605, avg. samples / sec: 2146.70
Iteration:   2880, Loss function: 4.225, Average Loss: 4.599, avg. samples / sec: 2145.84
Iteration:   2900, Loss function: 4.407, Average Loss: 4.595, avg. samples / sec: 2148.54
Iteration:   2920, Loss function: 4.434, Average Loss: 4.590, avg. samples / sec: 2143.98
:::MLL 1586757478.739 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1586757478.740 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 4.450, Average Loss: 4.585, avg. samples / sec: 2142.64
Iteration:   2960, Loss function: 4.506, Average Loss: 4.582, avg. samples / sec: 2140.13
Iteration:   2980, Loss function: 4.177, Average Loss: 4.575, avg. samples / sec: 2139.91
Iteration:   3000, Loss function: 4.196, Average Loss: 4.569, avg. samples / sec: 2134.03
Iteration:   3020, Loss function: 4.083, Average Loss: 4.564, avg. samples / sec: 2140.26
Iteration:   3040, Loss function: 3.906, Average Loss: 4.561, avg. samples / sec: 2142.28
Iteration:   3060, Loss function: 4.212, Average Loss: 4.556, avg. samples / sec: 2140.01
Iteration:   3080, Loss function: 4.219, Average Loss: 4.552, avg. samples / sec: 2146.33
Iteration:   3100, Loss function: 4.179, Average Loss: 4.549, avg. samples / sec: 2144.41
Iteration:   3120, Loss function: 4.620, Average Loss: 4.545, avg. samples / sec: 2131.91
Iteration:   3140, Loss function: 4.324, Average Loss: 4.541, avg. samples / sec: 2143.69
Iteration:   3160, Loss function: 4.319, Average Loss: 4.538, avg. samples / sec: 2144.78
:::MLL 1586757533.452 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1586757533.453 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:   3180, Loss function: 4.188, Average Loss: 4.533, avg. samples / sec: 2139.02
Iteration:   3200, Loss function: 4.292, Average Loss: 4.530, avg. samples / sec: 2146.67
Iteration:   3220, Loss function: 4.221, Average Loss: 4.525, avg. samples / sec: 2146.87
Iteration:   3240, Loss function: 4.292, Average Loss: 4.521, avg. samples / sec: 2150.87
Iteration:   3260, Loss function: 4.314, Average Loss: 4.517, avg. samples / sec: 2145.61
Iteration:   3280, Loss function: 4.489, Average Loss: 4.513, avg. samples / sec: 2146.25
Iteration:   3300, Loss function: 4.330, Average Loss: 4.509, avg. samples / sec: 2146.36
Iteration:   3320, Loss function: 4.153, Average Loss: 4.504, avg. samples / sec: 2146.92
Iteration:   3340, Loss function: 4.318, Average Loss: 4.499, avg. samples / sec: 2141.41
Iteration:   3360, Loss function: 4.295, Average Loss: 4.495, avg. samples / sec: 2147.73
Iteration:   3380, Loss function: 3.948, Average Loss: 4.490, avg. samples / sec: 2138.94
Iteration:   3400, Loss function: 4.185, Average Loss: 4.487, avg. samples / sec: 2142.30
Iteration:   3420, Loss function: 4.363, Average Loss: 4.483, avg. samples / sec: 2146.51
:::MLL 1586757588.277 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1586757588.278 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 4.205, Average Loss: 4.479, avg. samples / sec: 2131.48
Iteration:   3460, Loss function: 4.012, Average Loss: 4.474, avg. samples / sec: 2136.45
Iteration:   3480, Loss function: 4.345, Average Loss: 4.471, avg. samples / sec: 2143.65
Iteration:   3500, Loss function: 4.187, Average Loss: 4.466, avg. samples / sec: 2141.06
Iteration:   3520, Loss function: 4.330, Average Loss: 4.463, avg. samples / sec: 2137.47
Iteration:   3540, Loss function: 4.026, Average Loss: 4.459, avg. samples / sec: 2139.70
Iteration:   3560, Loss function: 4.138, Average Loss: 4.454, avg. samples / sec: 2140.18
Iteration:   3580, Loss function: 4.227, Average Loss: 4.450, avg. samples / sec: 2135.36
Iteration:   3600, Loss function: 4.128, Average Loss: 4.447, avg. samples / sec: 2132.42
Iteration:   3620, Loss function: 4.145, Average Loss: 4.442, avg. samples / sec: 2141.95
Iteration:   3640, Loss function: 3.899, Average Loss: 4.438, avg. samples / sec: 2137.16
Iteration:   3660, Loss function: 4.101, Average Loss: 4.433, avg. samples / sec: 2141.62
:::MLL 1586757643.048 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1586757643.049 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   3680, Loss function: 4.308, Average Loss: 4.431, avg. samples / sec: 2137.47
Iteration:   3700, Loss function: 4.230, Average Loss: 4.426, avg. samples / sec: 2135.69
Iteration:   3720, Loss function: 3.938, Average Loss: 4.422, avg. samples / sec: 2142.07
Iteration:   3740, Loss function: 3.967, Average Loss: 4.418, avg. samples / sec: 2133.78
Iteration:   3760, Loss function: 4.156, Average Loss: 4.414, avg. samples / sec: 2140.97
Iteration:   3780, Loss function: 4.139, Average Loss: 4.408, avg. samples / sec: 2145.80
Iteration:   3800, Loss function: 4.618, Average Loss: 4.405, avg. samples / sec: 2147.41
Iteration:   3820, Loss function: 4.568, Average Loss: 4.401, avg. samples / sec: 2150.38
Iteration:   3840, Loss function: 4.226, Average Loss: 4.397, avg. samples / sec: 2148.68
Iteration:   3860, Loss function: 3.893, Average Loss: 4.393, avg. samples / sec: 2148.41
Iteration:   3880, Loss function: 4.133, Average Loss: 4.390, avg. samples / sec: 2145.89
Iteration:   3900, Loss function: 4.040, Average Loss: 4.385, avg. samples / sec: 2144.97
:::MLL 1586757697.691 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1586757697.692 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 4.184, Average Loss: 4.381, avg. samples / sec: 2143.49
Iteration:   3940, Loss function: 4.015, Average Loss: 4.376, avg. samples / sec: 2152.39
Iteration:   3960, Loss function: 4.557, Average Loss: 4.372, avg. samples / sec: 2156.49
Iteration:   3980, Loss function: 4.004, Average Loss: 4.367, avg. samples / sec: 2154.14
Iteration:   4000, Loss function: 4.389, Average Loss: 4.364, avg. samples / sec: 2152.49
Iteration:   4020, Loss function: 4.331, Average Loss: 4.360, avg. samples / sec: 2146.91
Iteration:   4040, Loss function: 3.907, Average Loss: 4.356, avg. samples / sec: 2152.94
Iteration:   4060, Loss function: 4.400, Average Loss: 4.352, avg. samples / sec: 2151.70
Iteration:   4080, Loss function: 4.366, Average Loss: 4.349, avg. samples / sec: 2150.32
Iteration:   4100, Loss function: 4.170, Average Loss: 4.346, avg. samples / sec: 2145.47
Iteration:   4120, Loss function: 4.222, Average Loss: 4.343, avg. samples / sec: 2138.12
Iteration:   4140, Loss function: 4.137, Average Loss: 4.340, avg. samples / sec: 2143.55
:::MLL 1586757752.430 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1586757752.431 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   4160, Loss function: 4.223, Average Loss: 4.336, avg. samples / sec: 2134.48
Iteration:   4180, Loss function: 4.342, Average Loss: 4.333, avg. samples / sec: 2142.67
Iteration:   4200, Loss function: 4.205, Average Loss: 4.329, avg. samples / sec: 2141.45
Iteration:   4220, Loss function: 4.296, Average Loss: 4.327, avg. samples / sec: 2141.13
Iteration:   4240, Loss function: 4.160, Average Loss: 4.323, avg. samples / sec: 2137.64
Iteration:   4260, Loss function: 4.214, Average Loss: 4.319, avg. samples / sec: 2147.28
Iteration:   4280, Loss function: 4.232, Average Loss: 4.316, avg. samples / sec: 2148.75
Iteration:   4300, Loss function: 3.853, Average Loss: 4.314, avg. samples / sec: 2145.94
Iteration:   4320, Loss function: 4.020, Average Loss: 4.309, avg. samples / sec: 2144.34
Iteration:   4340, Loss function: 3.791, Average Loss: 4.305, avg. samples / sec: 2138.17
Iteration:   4360, Loss function: 4.081, Average Loss: 4.303, avg. samples / sec: 2143.36
Iteration:   4380, Loss function: 4.078, Average Loss: 4.299, avg. samples / sec: 2129.11
:::MLL 1586757807.116 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1586757807.116 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   4400, Loss function: 3.923, Average Loss: 4.296, avg. samples / sec: 2132.93
Iteration:   4420, Loss function: 3.813, Average Loss: 4.291, avg. samples / sec: 2140.63
Iteration:   4440, Loss function: 4.117, Average Loss: 4.286, avg. samples / sec: 2137.75
Iteration:   4460, Loss function: 4.064, Average Loss: 4.282, avg. samples / sec: 2143.61
Iteration:   4480, Loss function: 3.969, Average Loss: 4.278, avg. samples / sec: 2143.94
Iteration:   4500, Loss function: 3.985, Average Loss: 4.276, avg. samples / sec: 2143.06
Iteration:   4520, Loss function: 4.103, Average Loss: 4.271, avg. samples / sec: 2142.66
Iteration:   4540, Loss function: 3.982, Average Loss: 4.269, avg. samples / sec: 2139.92
Iteration:   4560, Loss function: 4.475, Average Loss: 4.266, avg. samples / sec: 2140.12
Iteration:   4580, Loss function: 3.956, Average Loss: 4.262, avg. samples / sec: 2140.97
Iteration:   4600, Loss function: 4.527, Average Loss: 4.258, avg. samples / sec: 2139.57
Iteration:   4620, Loss function: 4.190, Average Loss: 4.255, avg. samples / sec: 2143.80
Iteration:   4640, Loss function: 4.085, Average Loss: 4.252, avg. samples / sec: 2147.57
:::MLL 1586757861.816 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1586757861.816 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   4660, Loss function: 4.090, Average Loss: 4.248, avg. samples / sec: 2143.94
Iteration:   4680, Loss function: 3.910, Average Loss: 4.245, avg. samples / sec: 2145.21
Iteration:   4700, Loss function: 4.027, Average Loss: 4.240, avg. samples / sec: 2144.19
Iteration:   4720, Loss function: 4.040, Average Loss: 4.237, avg. samples / sec: 2140.87
Iteration:   4740, Loss function: 3.820, Average Loss: 4.235, avg. samples / sec: 2145.35
Iteration:   4760, Loss function: 3.928, Average Loss: 4.230, avg. samples / sec: 2142.75
Iteration:   4780, Loss function: 4.275, Average Loss: 4.227, avg. samples / sec: 2134.12
Iteration:   4800, Loss function: 4.075, Average Loss: 4.224, avg. samples / sec: 2143.39
Iteration:   4820, Loss function: 3.965, Average Loss: 4.220, avg. samples / sec: 2142.93
Iteration:   4840, Loss function: 3.974, Average Loss: 4.217, avg. samples / sec: 2141.19
Iteration:   4860, Loss function: 4.215, Average Loss: 4.216, avg. samples / sec: 2145.82
Iteration:   4880, Loss function: 3.865, Average Loss: 4.213, avg. samples / sec: 2140.67
:::MLL 1586757916.704 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1586757916.704 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   4900, Loss function: 3.913, Average Loss: 4.209, avg. samples / sec: 2137.71
Iteration:   4920, Loss function: 3.818, Average Loss: 4.206, avg. samples / sec: 2150.27
Iteration:   4940, Loss function: 4.160, Average Loss: 4.201, avg. samples / sec: 2141.85
Iteration:   4960, Loss function: 4.148, Average Loss: 4.198, avg. samples / sec: 2142.44
Iteration:   4980, Loss function: 4.269, Average Loss: 4.194, avg. samples / sec: 2137.19
Iteration:   5000, Loss function: 4.233, Average Loss: 4.191, avg. samples / sec: 2144.70
Iteration:   5020, Loss function: 4.068, Average Loss: 4.189, avg. samples / sec: 2144.44
Iteration:   5040, Loss function: 4.019, Average Loss: 4.186, avg. samples / sec: 2145.71
Iteration:   5060, Loss function: 4.021, Average Loss: 4.183, avg. samples / sec: 2142.45
Iteration:   5080, Loss function: 4.333, Average Loss: 4.181, avg. samples / sec: 2146.62
Iteration:   5100, Loss function: 4.091, Average Loss: 4.180, avg. samples / sec: 2140.92
Iteration:   5120, Loss function: 3.912, Average Loss: 4.177, avg. samples / sec: 2146.28
:::MLL 1586757971.358 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1586757971.358 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   5140, Loss function: 3.944, Average Loss: 4.174, avg. samples / sec: 2125.31
Iteration:   5160, Loss function: 3.783, Average Loss: 4.170, avg. samples / sec: 2148.71
Iteration:   5180, Loss function: 3.985, Average Loss: 4.166, avg. samples / sec: 2146.18
Iteration:   5200, Loss function: 4.100, Average Loss: 4.163, avg. samples / sec: 2146.25
Iteration:   5220, Loss function: 3.800, Average Loss: 4.160, avg. samples / sec: 2152.42
Iteration:   5240, Loss function: 4.106, Average Loss: 4.156, avg. samples / sec: 2150.69
Iteration:   5260, Loss function: 4.304, Average Loss: 4.153, avg. samples / sec: 2145.23
Iteration:   5280, Loss function: 4.440, Average Loss: 4.151, avg. samples / sec: 2142.45
Iteration:   5300, Loss function: 3.916, Average Loss: 4.149, avg. samples / sec: 2145.88
Iteration:   5320, Loss function: 4.034, Average Loss: 4.147, avg. samples / sec: 2150.52
Iteration:   5340, Loss function: 4.029, Average Loss: 4.146, avg. samples / sec: 2149.25
Iteration:   5360, Loss function: 3.845, Average Loss: 4.143, avg. samples / sec: 2146.42
:::MLL 1586758025.929 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1586758025.929 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   5380, Loss function: 4.126, Average Loss: 4.142, avg. samples / sec: 2141.92
Iteration:   5400, Loss function: 4.141, Average Loss: 4.138, avg. samples / sec: 2150.53
Iteration:   5420, Loss function: 4.364, Average Loss: 4.136, avg. samples / sec: 2142.83
Iteration:   5440, Loss function: 4.237, Average Loss: 4.133, avg. samples / sec: 2147.64
Iteration:   5460, Loss function: 4.085, Average Loss: 4.130, avg. samples / sec: 2151.82
Iteration:   5480, Loss function: 3.844, Average Loss: 4.127, avg. samples / sec: 2153.94
Iteration:   5500, Loss function: 4.051, Average Loss: 4.123, avg. samples / sec: 2153.95
Iteration:   5520, Loss function: 3.985, Average Loss: 4.121, avg. samples / sec: 2146.62
Iteration:   5540, Loss function: 4.292, Average Loss: 4.120, avg. samples / sec: 2152.61
Iteration:   5560, Loss function: 4.170, Average Loss: 4.117, avg. samples / sec: 2150.13
Iteration:   5580, Loss function: 3.984, Average Loss: 4.115, avg. samples / sec: 2147.86
Iteration:   5600, Loss function: 4.143, Average Loss: 4.113, avg. samples / sec: 2150.62
:::MLL 1586758080.418 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1586758080.419 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   5620, Loss function: 3.839, Average Loss: 4.110, avg. samples / sec: 2138.60
Iteration:   5640, Loss function: 3.919, Average Loss: 4.107, avg. samples / sec: 2149.24
Iteration:   5660, Loss function: 3.793, Average Loss: 4.104, avg. samples / sec: 2146.79
Iteration:   5680, Loss function: 4.125, Average Loss: 4.100, avg. samples / sec: 2146.25
Iteration:   5700, Loss function: 4.158, Average Loss: 4.099, avg. samples / sec: 2149.93
Iteration:   5720, Loss function: 4.247, Average Loss: 4.096, avg. samples / sec: 2150.64
Iteration:   5740, Loss function: 3.805, Average Loss: 4.094, avg. samples / sec: 2150.22
Iteration:   5760, Loss function: 3.853, Average Loss: 4.091, avg. samples / sec: 2148.76
Iteration:   5780, Loss function: 4.051, Average Loss: 4.090, avg. samples / sec: 2151.66
Iteration:   5800, Loss function: 4.253, Average Loss: 4.088, avg. samples / sec: 2149.43
Iteration:   5820, Loss function: 3.755, Average Loss: 4.087, avg. samples / sec: 2150.61
Iteration:   5840, Loss function: 3.869, Average Loss: 4.084, avg. samples / sec: 2150.66
Iteration:   5860, Loss function: 4.029, Average Loss: 4.082, avg. samples / sec: 2148.52
:::MLL 1586758135.156 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1586758135.156 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   5880, Loss function: 4.002, Average Loss: 4.079, avg. samples / sec: 2134.83
Iteration:   5900, Loss function: 3.876, Average Loss: 4.075, avg. samples / sec: 2151.87
Iteration:   5920, Loss function: 3.922, Average Loss: 4.072, avg. samples / sec: 2149.33
Iteration:   5940, Loss function: 3.715, Average Loss: 4.070, avg. samples / sec: 2150.04
Iteration:   5960, Loss function: 4.091, Average Loss: 4.069, avg. samples / sec: 2146.18
Iteration:   5980, Loss function: 3.901, Average Loss: 4.066, avg. samples / sec: 2151.56
Iteration:   6000, Loss function: 3.718, Average Loss: 4.064, avg. samples / sec: 2147.54
Iteration:   6020, Loss function: 3.837, Average Loss: 4.061, avg. samples / sec: 2140.74
Iteration:   6040, Loss function: 3.916, Average Loss: 4.058, avg. samples / sec: 2151.16
Iteration:   6060, Loss function: 3.941, Average Loss: 4.056, avg. samples / sec: 2141.86
Iteration:   6080, Loss function: 3.834, Average Loss: 4.055, avg. samples / sec: 2155.95
Iteration:   6100, Loss function: 3.884, Average Loss: 4.053, avg. samples / sec: 2150.93
:::MLL 1586758189.683 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1586758189.684 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   6120, Loss function: 4.026, Average Loss: 4.052, avg. samples / sec: 2149.97
Iteration:   6140, Loss function: 3.837, Average Loss: 4.048, avg. samples / sec: 2150.85
Iteration:   6160, Loss function: 3.656, Average Loss: 4.045, avg. samples / sec: 2152.76
Iteration:   6180, Loss function: 4.126, Average Loss: 4.043, avg. samples / sec: 2151.23
Iteration:   6200, Loss function: 3.518, Average Loss: 4.041, avg. samples / sec: 2153.77
Iteration:   6220, Loss function: 3.722, Average Loss: 4.038, avg. samples / sec: 2149.52
Iteration:   6240, Loss function: 3.760, Average Loss: 4.035, avg. samples / sec: 2138.34
Iteration:   6260, Loss function: 4.211, Average Loss: 4.033, avg. samples / sec: 2141.52
Iteration:   6280, Loss function: 3.889, Average Loss: 4.032, avg. samples / sec: 2144.49
Iteration:   6300, Loss function: 3.621, Average Loss: 4.029, avg. samples / sec: 2142.19
Iteration:   6320, Loss function: 4.001, Average Loss: 4.028, avg. samples / sec: 2144.42
Iteration:   6340, Loss function: 3.932, Average Loss: 4.027, avg. samples / sec: 2143.35
:::MLL 1586758244.242 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1586758244.243 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   6360, Loss function: 3.781, Average Loss: 4.024, avg. samples / sec: 2142.96
Iteration:   6380, Loss function: 3.797, Average Loss: 4.021, avg. samples / sec: 2145.25
Iteration:   6400, Loss function: 3.861, Average Loss: 4.018, avg. samples / sec: 2148.96
Iteration:   6420, Loss function: 3.642, Average Loss: 4.015, avg. samples / sec: 2147.31
Iteration:   6440, Loss function: 3.794, Average Loss: 4.012, avg. samples / sec: 2144.85
Iteration:   6460, Loss function: 3.943, Average Loss: 4.010, avg. samples / sec: 2147.91
Iteration:   6480, Loss function: 3.837, Average Loss: 4.008, avg. samples / sec: 2141.91
Iteration:   6500, Loss function: 3.784, Average Loss: 4.006, avg. samples / sec: 2151.48
Iteration:   6520, Loss function: 3.824, Average Loss: 4.005, avg. samples / sec: 2151.82
Iteration:   6540, Loss function: 3.782, Average Loss: 4.003, avg. samples / sec: 2151.41
Iteration:   6560, Loss function: 3.886, Average Loss: 4.003, avg. samples / sec: 2145.46
Iteration:   6580, Loss function: 3.889, Average Loss: 4.002, avg. samples / sec: 2149.58
:::MLL 1586758299.013 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1586758299.014 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   6600, Loss function: 3.650, Average Loss: 4.000, avg. samples / sec: 2137.74
Iteration:   6620, Loss function: 4.094, Average Loss: 3.998, avg. samples / sec: 2144.62
Iteration:   6640, Loss function: 3.927, Average Loss: 3.996, avg. samples / sec: 2138.68
Iteration:   6660, Loss function: 4.081, Average Loss: 3.993, avg. samples / sec: 2152.42
Iteration:   6680, Loss function: 3.792, Average Loss: 3.991, avg. samples / sec: 2138.85
Iteration:   6700, Loss function: 4.133, Average Loss: 3.989, avg. samples / sec: 2146.29
Iteration:   6720, Loss function: 3.898, Average Loss: 3.987, avg. samples / sec: 2143.54
Iteration:   6740, Loss function: 3.913, Average Loss: 3.985, avg. samples / sec: 2148.19
Iteration:   6760, Loss function: 3.769, Average Loss: 3.983, avg. samples / sec: 2146.35
Iteration:   6780, Loss function: 4.149, Average Loss: 3.981, avg. samples / sec: 2151.71
Iteration:   6800, Loss function: 3.813, Average Loss: 3.981, avg. samples / sec: 2142.97
Iteration:   6820, Loss function: 3.995, Average Loss: 3.979, avg. samples / sec: 2145.53
Iteration:   6840, Loss function: 3.474, Average Loss: 3.977, avg. samples / sec: 2147.53
:::MLL 1586758353.620 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1586758353.620 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   6860, Loss function: 3.645, Average Loss: 3.974, avg. samples / sec: 2125.36
Iteration:   6880, Loss function: 4.097, Average Loss: 3.973, avg. samples / sec: 2145.45
Iteration:   6900, Loss function: 3.832, Average Loss: 3.970, avg. samples / sec: 2148.20
Iteration:   6920, Loss function: 3.991, Average Loss: 3.969, avg. samples / sec: 2138.45
Iteration:   6940, Loss function: 3.539, Average Loss: 3.967, avg. samples / sec: 2143.56
Iteration:   6960, Loss function: 3.888, Average Loss: 3.965, avg. samples / sec: 2143.18
Iteration:   6980, Loss function: 4.011, Average Loss: 3.963, avg. samples / sec: 2148.54
Iteration:   7000, Loss function: 3.745, Average Loss: 3.962, avg. samples / sec: 2148.84
Iteration:   7020, Loss function: 3.861, Average Loss: 3.961, avg. samples / sec: 2144.53
Iteration:   7040, Loss function: 3.729, Average Loss: 3.958, avg. samples / sec: 2145.18
Iteration:   7060, Loss function: 3.915, Average Loss: 3.957, avg. samples / sec: 2146.62
Iteration:   7080, Loss function: 3.872, Average Loss: 3.955, avg. samples / sec: 2141.66
:::MLL 1586758408.256 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1586758408.257 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   7100, Loss function: 3.933, Average Loss: 3.953, avg. samples / sec: 2143.10
Iteration:   7120, Loss function: 3.955, Average Loss: 3.950, avg. samples / sec: 2141.75
Iteration:   7140, Loss function: 3.773, Average Loss: 3.948, avg. samples / sec: 2143.08
Iteration:   7160, Loss function: 3.704, Average Loss: 3.946, avg. samples / sec: 2152.12
Iteration:   7180, Loss function: 4.286, Average Loss: 3.945, avg. samples / sec: 2147.08
Iteration:   7200, Loss function: 3.690, Average Loss: 3.943, avg. samples / sec: 2136.05
Iteration:   7220, Loss function: 4.220, Average Loss: 3.942, avg. samples / sec: 2142.11
Iteration:   7240, Loss function: 3.668, Average Loss: 3.941, avg. samples / sec: 2144.67
Iteration:   7260, Loss function: 3.848, Average Loss: 3.938, avg. samples / sec: 2140.62
Iteration:   7280, Loss function: 4.135, Average Loss: 3.937, avg. samples / sec: 2143.41
Iteration:   7300, Loss function: 3.767, Average Loss: 3.935, avg. samples / sec: 2146.29
Iteration:   7320, Loss function: 3.984, Average Loss: 3.935, avg. samples / sec: 2143.75
:::MLL 1586758463.120 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1586758463.121 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   7340, Loss function: 3.760, Average Loss: 3.934, avg. samples / sec: 2144.27
Iteration:   7360, Loss function: 3.670, Average Loss: 3.932, avg. samples / sec: 2146.93
Iteration:   7380, Loss function: 3.763, Average Loss: 3.930, avg. samples / sec: 2148.14
Iteration:   7400, Loss function: 3.517, Average Loss: 3.928, avg. samples / sec: 2138.43
Iteration:   7420, Loss function: 3.801, Average Loss: 3.926, avg. samples / sec: 2137.21
Iteration:   7440, Loss function: 3.695, Average Loss: 3.924, avg. samples / sec: 2139.61
Iteration:   7460, Loss function: 3.862, Average Loss: 3.923, avg. samples / sec: 2135.80
Iteration:   7480, Loss function: 3.795, Average Loss: 3.923, avg. samples / sec: 2147.53
Iteration:   7500, Loss function: 3.639, Average Loss: 3.923, avg. samples / sec: 2144.29
Iteration:   7520, Loss function: 3.717, Average Loss: 3.922, avg. samples / sec: 2137.23
Iteration:   7540, Loss function: 3.805, Average Loss: 3.920, avg. samples / sec: 2145.03
Iteration:   7560, Loss function: 3.523, Average Loss: 3.919, avg. samples / sec: 2143.56
:::MLL 1586758517.792 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1586758517.792 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   7580, Loss function: 3.950, Average Loss: 3.916, avg. samples / sec: 2140.55
Iteration:   7600, Loss function: 3.506, Average Loss: 3.914, avg. samples / sec: 2150.55
Iteration:   7620, Loss function: 3.835, Average Loss: 3.912, avg. samples / sec: 2149.37
Iteration:   7640, Loss function: 3.575, Average Loss: 3.910, avg. samples / sec: 2143.36
Iteration:   7660, Loss function: 3.914, Average Loss: 3.908, avg. samples / sec: 2136.11
Iteration:   7680, Loss function: 3.741, Average Loss: 3.906, avg. samples / sec: 2148.40
Iteration:   7700, Loss function: 3.930, Average Loss: 3.903, avg. samples / sec: 2148.85
Iteration:   7720, Loss function: 3.805, Average Loss: 3.903, avg. samples / sec: 2149.57
Iteration:   7740, Loss function: 3.794, Average Loss: 3.901, avg. samples / sec: 2140.54
Iteration:   7760, Loss function: 3.649, Average Loss: 3.899, avg. samples / sec: 2145.64
Iteration:   7780, Loss function: 3.893, Average Loss: 3.898, avg. samples / sec: 2139.52
Iteration:   7800, Loss function: 4.000, Average Loss: 3.896, avg. samples / sec: 2146.71
:::MLL 1586758572.404 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1586758572.404 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   7820, Loss function: 3.743, Average Loss: 3.894, avg. samples / sec: 2134.76
Iteration:   7840, Loss function: 3.723, Average Loss: 3.892, avg. samples / sec: 2148.62
Iteration:   7860, Loss function: 3.752, Average Loss: 3.891, avg. samples / sec: 2144.19
Iteration:   7880, Loss function: 3.851, Average Loss: 3.889, avg. samples / sec: 2144.22
Iteration:   7900, Loss function: 3.517, Average Loss: 3.885, avg. samples / sec: 2149.04
Iteration:   7920, Loss function: 3.818, Average Loss: 3.883, avg. samples / sec: 2144.40
Iteration:   7940, Loss function: 3.721, Average Loss: 3.880, avg. samples / sec: 2142.55
Iteration:   7960, Loss function: 3.698, Average Loss: 3.878, avg. samples / sec: 2141.86
Iteration:   7980, Loss function: 3.910, Average Loss: 3.876, avg. samples / sec: 2138.89
Iteration:   8000, Loss function: 3.806, Average Loss: 3.875, avg. samples / sec: 2142.83
:::MLL 1586758613.387 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 6/8Parsing batch: 7/8Predicting Ended, total time: 11.81 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.45s)
DONE (t=0.46s)
DONE (t=0.47s)
DONE (t=0.51s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.26s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17602
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32500
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17215
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04604
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.28509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18720
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29031
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08402
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31255
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.45095
Current AP: 0.17602 AP goal: 0.23000
:::MLL 1586758629.056 eval_accuracy: {"value": 0.17601951212656858, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1586758629.057 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1586758629.081 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1586758629.081 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   8020, Loss function: 3.879, Average Loss: 3.875, avg. samples / sec: 475.68
Iteration:   8040, Loss function: 4.033, Average Loss: 3.875, avg. samples / sec: 2151.68
Iteration:   8060, Loss function: 3.814, Average Loss: 3.874, avg. samples / sec: 2158.07
:::MLL 1586758642.923 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1586758642.923 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   8080, Loss function: 3.815, Average Loss: 3.873, avg. samples / sec: 2151.14
Iteration:   8100, Loss function: 3.556, Average Loss: 3.872, avg. samples / sec: 2156.51
Iteration:   8120, Loss function: 3.631, Average Loss: 3.870, avg. samples / sec: 2151.86
Iteration:   8140, Loss function: 3.602, Average Loss: 3.869, avg. samples / sec: 2149.61
Iteration:   8160, Loss function: 4.216, Average Loss: 3.869, avg. samples / sec: 2153.24
Iteration:   8180, Loss function: 3.633, Average Loss: 3.867, avg. samples / sec: 2143.43
Iteration:   8200, Loss function: 3.865, Average Loss: 3.866, avg. samples / sec: 2148.70
Iteration:   8220, Loss function: 3.917, Average Loss: 3.867, avg. samples / sec: 2146.06
Iteration:   8240, Loss function: 3.665, Average Loss: 3.865, avg. samples / sec: 2153.46
Iteration:   8260, Loss function: 3.591, Average Loss: 3.864, avg. samples / sec: 2144.41
Iteration:   8280, Loss function: 3.571, Average Loss: 3.863, avg. samples / sec: 2149.93
Iteration:   8300, Loss function: 3.813, Average Loss: 3.862, avg. samples / sec: 2128.90
:::MLL 1586758697.447 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1586758697.448 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   8320, Loss function: 3.746, Average Loss: 3.862, avg. samples / sec: 2141.18
Iteration:   8340, Loss function: 3.661, Average Loss: 3.860, avg. samples / sec: 2147.18
Iteration:   8360, Loss function: 3.875, Average Loss: 3.859, avg. samples / sec: 2141.83
Iteration:   8380, Loss function: 3.723, Average Loss: 3.857, avg. samples / sec: 2145.27
Iteration:   8400, Loss function: 3.863, Average Loss: 3.855, avg. samples / sec: 2146.92
Iteration:   8420, Loss function: 3.885, Average Loss: 3.853, avg. samples / sec: 2147.59
Iteration:   8440, Loss function: 3.550, Average Loss: 3.852, avg. samples / sec: 2144.83
Iteration:   8460, Loss function: 3.763, Average Loss: 3.851, avg. samples / sec: 2143.95
Iteration:   8480, Loss function: 3.682, Average Loss: 3.850, avg. samples / sec: 2140.89
Iteration:   8500, Loss function: 4.008, Average Loss: 3.851, avg. samples / sec: 2130.11
Iteration:   8520, Loss function: 3.756, Average Loss: 3.849, avg. samples / sec: 2141.64
Iteration:   8540, Loss function: 3.884, Average Loss: 3.848, avg. samples / sec: 2139.08
:::MLL 1586758752.112 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1586758752.112 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   8560, Loss function: 3.633, Average Loss: 3.847, avg. samples / sec: 2140.49
Iteration:   8580, Loss function: 3.637, Average Loss: 3.845, avg. samples / sec: 2147.78
Iteration:   8600, Loss function: 3.933, Average Loss: 3.844, avg. samples / sec: 2134.76
Iteration:   8620, Loss function: 3.779, Average Loss: 3.842, avg. samples / sec: 2139.10
Iteration:   8640, Loss function: 3.805, Average Loss: 3.840, avg. samples / sec: 2134.16
Iteration:   8660, Loss function: 3.998, Average Loss: 3.840, avg. samples / sec: 2140.96
Iteration:   8680, Loss function: 3.689, Average Loss: 3.840, avg. samples / sec: 2141.11
Iteration:   8700, Loss function: 3.912, Average Loss: 3.838, avg. samples / sec: 2144.00
Iteration:   8720, Loss function: 3.624, Average Loss: 3.837, avg. samples / sec: 2139.27
Iteration:   8740, Loss function: 3.806, Average Loss: 3.836, avg. samples / sec: 2141.99
Iteration:   8760, Loss function: 3.777, Average Loss: 3.836, avg. samples / sec: 2142.66
Iteration:   8780, Loss function: 3.720, Average Loss: 3.836, avg. samples / sec: 2143.44
:::MLL 1586758806.831 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1586758806.831 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   8800, Loss function: 3.877, Average Loss: 3.836, avg. samples / sec: 2136.02
Iteration:   8820, Loss function: 3.778, Average Loss: 3.834, avg. samples / sec: 2141.77
Iteration:   8840, Loss function: 3.611, Average Loss: 3.833, avg. samples / sec: 2133.72
Iteration:   8860, Loss function: 4.011, Average Loss: 3.831, avg. samples / sec: 2143.02
Iteration:   8880, Loss function: 3.758, Average Loss: 3.828, avg. samples / sec: 2139.10
Iteration:   8900, Loss function: 3.472, Average Loss: 3.827, avg. samples / sec: 2141.26
Iteration:   8920, Loss function: 3.745, Average Loss: 3.826, avg. samples / sec: 2137.39
Iteration:   8940, Loss function: 3.919, Average Loss: 3.825, avg. samples / sec: 2136.54
Iteration:   8960, Loss function: 3.730, Average Loss: 3.824, avg. samples / sec: 2137.32
Iteration:   8980, Loss function: 3.792, Average Loss: 3.823, avg. samples / sec: 2139.87
Iteration:   9000, Loss function: 3.808, Average Loss: 3.823, avg. samples / sec: 2137.84
Iteration:   9020, Loss function: 3.490, Average Loss: 3.821, avg. samples / sec: 2139.82
:::MLL 1586758861.816 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1586758861.816 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   9040, Loss function: 4.010, Average Loss: 3.820, avg. samples / sec: 2128.10
Iteration:   9060, Loss function: 3.785, Average Loss: 3.819, avg. samples / sec: 2127.80
Iteration:   9080, Loss function: 3.578, Average Loss: 3.818, avg. samples / sec: 2143.76
Iteration:   9100, Loss function: 3.716, Average Loss: 3.816, avg. samples / sec: 2138.78
Iteration:   9120, Loss function: 3.923, Average Loss: 3.815, avg. samples / sec: 2139.93
Iteration:   9140, Loss function: 3.362, Average Loss: 3.814, avg. samples / sec: 2136.93
Iteration:   9160, Loss function: 3.726, Average Loss: 3.813, avg. samples / sec: 2142.75
Iteration:   9180, Loss function: 3.816, Average Loss: 3.812, avg. samples / sec: 2142.55
Iteration:   9200, Loss function: 3.622, Average Loss: 3.811, avg. samples / sec: 2128.24
Iteration:   9220, Loss function: 3.638, Average Loss: 3.810, avg. samples / sec: 2133.51
Iteration:   9240, Loss function: 3.735, Average Loss: 3.809, avg. samples / sec: 2139.10
Iteration:   9260, Loss function: 3.973, Average Loss: 3.808, avg. samples / sec: 2136.65
Iteration:   9280, Loss function: 3.846, Average Loss: 3.807, avg. samples / sec: 2144.55
:::MLL 1586758916.638 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1586758916.639 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   9300, Loss function: 3.775, Average Loss: 3.804, avg. samples / sec: 2130.18
Iteration:   9320, Loss function: 3.600, Average Loss: 3.802, avg. samples / sec: 2143.85
Iteration:   9340, Loss function: 3.740, Average Loss: 3.800, avg. samples / sec: 2135.42
Iteration:   9360, Loss function: 3.883, Average Loss: 3.800, avg. samples / sec: 2127.47
Iteration:   9380, Loss function: 3.631, Average Loss: 3.799, avg. samples / sec: 2137.31
Iteration:   9400, Loss function: 3.742, Average Loss: 3.797, avg. samples / sec: 2134.84
Iteration:   9420, Loss function: 4.008, Average Loss: 3.796, avg. samples / sec: 2141.04
Iteration:   9440, Loss function: 3.670, Average Loss: 3.794, avg. samples / sec: 2138.74
Iteration:   9460, Loss function: 3.670, Average Loss: 3.792, avg. samples / sec: 2134.42
Iteration:   9480, Loss function: 3.737, Average Loss: 3.791, avg. samples / sec: 2143.59
Iteration:   9500, Loss function: 3.694, Average Loss: 3.790, avg. samples / sec: 2139.03
Iteration:   9520, Loss function: 3.756, Average Loss: 3.789, avg. samples / sec: 2125.53
:::MLL 1586758971.456 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1586758971.457 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   9540, Loss function: 3.403, Average Loss: 3.788, avg. samples / sec: 2135.92
Iteration:   9560, Loss function: 3.366, Average Loss: 3.787, avg. samples / sec: 2140.17
Iteration:   9580, Loss function: 3.795, Average Loss: 3.784, avg. samples / sec: 2143.63
Iteration:   9600, Loss function: 3.578, Average Loss: 3.784, avg. samples / sec: 2139.52
Iteration:   9620, Loss function: 3.474, Average Loss: 3.782, avg. samples / sec: 2135.91
Iteration:   9640, Loss function: 3.703, Average Loss: 3.781, avg. samples / sec: 2141.90
Iteration:   9660, Loss function: 3.779, Average Loss: 3.780, avg. samples / sec: 2141.91
Iteration:   9680, Loss function: 3.716, Average Loss: 3.779, avg. samples / sec: 2139.27
Iteration:   9700, Loss function: 3.817, Average Loss: 3.778, avg. samples / sec: 2144.13
Iteration:   9720, Loss function: 3.892, Average Loss: 3.779, avg. samples / sec: 2133.57
Iteration:   9740, Loss function: 3.622, Average Loss: 3.779, avg. samples / sec: 2141.99
Iteration:   9760, Loss function: 3.874, Average Loss: 3.779, avg. samples / sec: 2140.07
:::MLL 1586759026.432 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1586759026.432 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   9780, Loss function: 3.651, Average Loss: 3.777, avg. samples / sec: 2125.76
Iteration:   9800, Loss function: 3.638, Average Loss: 3.775, avg. samples / sec: 2139.29
Iteration:   9820, Loss function: 3.818, Average Loss: 3.774, avg. samples / sec: 2134.99
Iteration:   9840, Loss function: 3.982, Average Loss: 3.772, avg. samples / sec: 2135.46
Iteration:   9860, Loss function: 3.913, Average Loss: 3.770, avg. samples / sec: 2142.10
Iteration:   9880, Loss function: 3.811, Average Loss: 3.769, avg. samples / sec: 2137.73
Iteration:   9900, Loss function: 3.567, Average Loss: 3.769, avg. samples / sec: 2135.66
Iteration:   9920, Loss function: 3.453, Average Loss: 3.767, avg. samples / sec: 2144.05
Iteration:   9940, Loss function: 3.865, Average Loss: 3.767, avg. samples / sec: 2145.05
Iteration:   9960, Loss function: 3.485, Average Loss: 3.767, avg. samples / sec: 2142.94
Iteration:   9980, Loss function: 3.699, Average Loss: 3.767, avg. samples / sec: 2141.72
Iteration:  10000, Loss function: 4.049, Average Loss: 3.767, avg. samples / sec: 2147.54
:::MLL 1586759081.147 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1586759081.147 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:  10020, Loss function: 3.740, Average Loss: 3.766, avg. samples / sec: 2144.57
Iteration:  10040, Loss function: 3.923, Average Loss: 3.765, avg. samples / sec: 2146.47
Iteration:  10060, Loss function: 3.738, Average Loss: 3.764, avg. samples / sec: 2140.26
Iteration:  10080, Loss function: 3.614, Average Loss: 3.763, avg. samples / sec: 2148.11
Iteration:  10100, Loss function: 3.776, Average Loss: 3.762, avg. samples / sec: 2144.70
Iteration:  10120, Loss function: 3.638, Average Loss: 3.761, avg. samples / sec: 2141.42
Iteration:  10140, Loss function: 3.661, Average Loss: 3.759, avg. samples / sec: 2139.41
Iteration:  10160, Loss function: 4.133, Average Loss: 3.760, avg. samples / sec: 2129.38
Iteration:  10180, Loss function: 3.688, Average Loss: 3.758, avg. samples / sec: 2136.46
Iteration:  10200, Loss function: 3.733, Average Loss: 3.757, avg. samples / sec: 2141.17
Iteration:  10220, Loss function: 4.013, Average Loss: 3.756, avg. samples / sec: 2132.96
Iteration:  10240, Loss function: 3.638, Average Loss: 3.755, avg. samples / sec: 2142.38
Iteration:  10260, Loss function: 3.687, Average Loss: 3.754, avg. samples / sec: 2141.98
:::MLL 1586759135.874 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1586759135.874 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:  10280, Loss function: 3.936, Average Loss: 3.752, avg. samples / sec: 2137.95
Iteration:  10300, Loss function: 3.846, Average Loss: 3.751, avg. samples / sec: 2140.68
Iteration:  10320, Loss function: 3.659, Average Loss: 3.749, avg. samples / sec: 2145.40
Iteration:  10340, Loss function: 3.434, Average Loss: 3.747, avg. samples / sec: 2142.76
Iteration:  10360, Loss function: 3.967, Average Loss: 3.747, avg. samples / sec: 2142.44
Iteration:  10380, Loss function: 3.498, Average Loss: 3.745, avg. samples / sec: 2142.46
Iteration:  10400, Loss function: 3.698, Average Loss: 3.743, avg. samples / sec: 2140.23
Iteration:  10420, Loss function: 3.662, Average Loss: 3.741, avg. samples / sec: 2143.00
Iteration:  10440, Loss function: 3.697, Average Loss: 3.741, avg. samples / sec: 2138.06
Iteration:  10460, Loss function: 3.527, Average Loss: 3.740, avg. samples / sec: 2139.61
Iteration:  10480, Loss function: 3.891, Average Loss: 3.739, avg. samples / sec: 2140.86
Iteration:  10500, Loss function: 3.503, Average Loss: 3.739, avg. samples / sec: 2145.43
:::MLL 1586759190.792 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1586759190.793 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:  10520, Loss function: 3.631, Average Loss: 3.737, avg. samples / sec: 2122.16
Iteration:  10540, Loss function: 3.707, Average Loss: 3.735, avg. samples / sec: 2140.26
Iteration:  10560, Loss function: 3.861, Average Loss: 3.734, avg. samples / sec: 2138.72
Iteration:  10580, Loss function: 3.457, Average Loss: 3.732, avg. samples / sec: 2140.20
Iteration:  10600, Loss function: 3.511, Average Loss: 3.730, avg. samples / sec: 2138.25
Iteration:  10620, Loss function: 3.784, Average Loss: 3.729, avg. samples / sec: 2135.14
Iteration:  10640, Loss function: 3.769, Average Loss: 3.729, avg. samples / sec: 2137.09
Iteration:  10660, Loss function: 3.672, Average Loss: 3.728, avg. samples / sec: 2135.92
lr decay step #1
:::MLL 1586759226.965 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 1/8Parsing batch: 3/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 2/8Parsing batch: 4/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 3/8Parsing batch: 5/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 4/8Parsing batch: 6/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 5/8Parsing batch: 7/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 10.69 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.51s)
DONE (t=0.51s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=0.53s)
DONE (t=2.43s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.18587
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.18596
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.19395
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.30402
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.19242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27843
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29278
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08119
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30747
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.46558
Current AP: 0.18587 AP goal: 0.23000
:::MLL 1586759240.652 eval_accuracy: {"value": 0.18586617398740443, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1586759240.713 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1586759240.732 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1586759240.733 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:  10680, Loss function: 3.471, Average Loss: 3.726, avg. samples / sec: 525.95
Iteration:  10700, Loss function: 3.829, Average Loss: 3.722, avg. samples / sec: 2151.69
Iteration:  10720, Loss function: 3.300, Average Loss: 3.717, avg. samples / sec: 2156.96
Iteration:  10740, Loss function: 3.544, Average Loss: 3.712, avg. samples / sec: 2144.10
:::MLL 1586759259.273 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1586759259.274 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:  10760, Loss function: 3.227, Average Loss: 3.707, avg. samples / sec: 2147.32
Iteration:  10780, Loss function: 3.304, Average Loss: 3.701, avg. samples / sec: 2155.90
Iteration:  10800, Loss function: 3.322, Average Loss: 3.694, avg. samples / sec: 2145.84
Iteration:  10820, Loss function: 3.406, Average Loss: 3.686, avg. samples / sec: 2147.68
Iteration:  10840, Loss function: 3.224, Average Loss: 3.679, avg. samples / sec: 2155.44
Iteration:  10860, Loss function: 3.060, Average Loss: 3.673, avg. samples / sec: 2146.00
Iteration:  10880, Loss function: 3.326, Average Loss: 3.667, avg. samples / sec: 2146.31
Iteration:  10900, Loss function: 3.370, Average Loss: 3.661, avg. samples / sec: 2140.85
Iteration:  10920, Loss function: 3.501, Average Loss: 3.655, avg. samples / sec: 2150.27
Iteration:  10940, Loss function: 3.023, Average Loss: 3.648, avg. samples / sec: 2142.95
Iteration:  10960, Loss function: 3.360, Average Loss: 3.641, avg. samples / sec: 2151.53
Iteration:  10980, Loss function: 3.241, Average Loss: 3.635, avg. samples / sec: 2152.98
:::MLL 1586759313.785 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1586759313.785 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:  11000, Loss function: 3.178, Average Loss: 3.629, avg. samples / sec: 2134.77
Iteration:  11020, Loss function: 3.300, Average Loss: 3.623, avg. samples / sec: 2148.44
Iteration:  11040, Loss function: 3.094, Average Loss: 3.616, avg. samples / sec: 2152.14
Iteration:  11060, Loss function: 3.126, Average Loss: 3.610, avg. samples / sec: 2149.15
Iteration:  11080, Loss function: 3.386, Average Loss: 3.605, avg. samples / sec: 2146.57
Iteration:  11100, Loss function: 3.243, Average Loss: 3.598, avg. samples / sec: 2136.30
Iteration:  11120, Loss function: 3.370, Average Loss: 3.593, avg. samples / sec: 2127.69
Iteration:  11140, Loss function: 3.474, Average Loss: 3.588, avg. samples / sec: 2143.85
Iteration:  11160, Loss function: 3.350, Average Loss: 3.582, avg. samples / sec: 2143.34
Iteration:  11180, Loss function: 3.274, Average Loss: 3.578, avg. samples / sec: 2142.61
Iteration:  11200, Loss function: 3.193, Average Loss: 3.573, avg. samples / sec: 2133.27
Iteration:  11220, Loss function: 3.409, Average Loss: 3.566, avg. samples / sec: 2136.81
:::MLL 1586759368.507 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1586759368.508 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:  11240, Loss function: 3.097, Average Loss: 3.561, avg. samples / sec: 2126.92
Iteration:  11260, Loss function: 3.194, Average Loss: 3.556, avg. samples / sec: 2138.09
Iteration:  11280, Loss function: 3.291, Average Loss: 3.552, avg. samples / sec: 2131.97
Iteration:  11300, Loss function: 3.367, Average Loss: 3.547, avg. samples / sec: 2140.65
Iteration:  11320, Loss function: 3.003, Average Loss: 3.541, avg. samples / sec: 2147.87
Iteration:  11340, Loss function: 3.114, Average Loss: 3.536, avg. samples / sec: 2140.97
Iteration:  11360, Loss function: 3.446, Average Loss: 3.532, avg. samples / sec: 2138.30
Iteration:  11380, Loss function: 3.015, Average Loss: 3.526, avg. samples / sec: 2138.86
Iteration:  11400, Loss function: 3.367, Average Loss: 3.521, avg. samples / sec: 2142.01
Iteration:  11420, Loss function: 3.199, Average Loss: 3.516, avg. samples / sec: 2142.34
Iteration:  11440, Loss function: 3.454, Average Loss: 3.511, avg. samples / sec: 2135.44
Iteration:  11460, Loss function: 3.312, Average Loss: 3.506, avg. samples / sec: 2139.97
Iteration:  11480, Loss function: 3.099, Average Loss: 3.503, avg. samples / sec: 2145.94
:::MLL 1586759423.475 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1586759423.476 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:  11500, Loss function: 3.134, Average Loss: 3.498, avg. samples / sec: 2136.59
Iteration:  11520, Loss function: 3.300, Average Loss: 3.494, avg. samples / sec: 2141.42
Iteration:  11540, Loss function: 3.302, Average Loss: 3.491, avg. samples / sec: 2137.73
Iteration:  11560, Loss function: 3.082, Average Loss: 3.487, avg. samples / sec: 2144.03
Iteration:  11580, Loss function: 3.277, Average Loss: 3.484, avg. samples / sec: 2140.67
Iteration:  11600, Loss function: 3.295, Average Loss: 3.480, avg. samples / sec: 2139.98
Iteration:  11620, Loss function: 3.471, Average Loss: 3.477, avg. samples / sec: 2143.20
Iteration:  11640, Loss function: 3.398, Average Loss: 3.472, avg. samples / sec: 2145.59
Iteration:  11660, Loss function: 3.132, Average Loss: 3.468, avg. samples / sec: 2145.04
Iteration:  11680, Loss function: 3.397, Average Loss: 3.464, avg. samples / sec: 2145.56
Iteration:  11700, Loss function: 3.162, Average Loss: 3.459, avg. samples / sec: 2133.47
Iteration:  11720, Loss function: 3.321, Average Loss: 3.455, avg. samples / sec: 2133.62
:::MLL 1586759478.190 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1586759478.191 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:  11740, Loss function: 3.456, Average Loss: 3.450, avg. samples / sec: 2134.55
Iteration:  11760, Loss function: 3.187, Average Loss: 3.446, avg. samples / sec: 2141.97
Iteration:  11780, Loss function: 3.099, Average Loss: 3.441, avg. samples / sec: 2144.38
Iteration:  11800, Loss function: 3.163, Average Loss: 3.437, avg. samples / sec: 2134.88
Iteration:  11820, Loss function: 3.056, Average Loss: 3.435, avg. samples / sec: 2136.68
Iteration:  11840, Loss function: 3.039, Average Loss: 3.430, avg. samples / sec: 2145.20
Iteration:  11860, Loss function: 3.301, Average Loss: 3.425, avg. samples / sec: 2143.99
Iteration:  11880, Loss function: 3.201, Average Loss: 3.420, avg. samples / sec: 2137.13
Iteration:  11900, Loss function: 3.145, Average Loss: 3.418, avg. samples / sec: 2148.38
Iteration:  11920, Loss function: 3.013, Average Loss: 3.415, avg. samples / sec: 2149.34
Iteration:  11940, Loss function: 2.953, Average Loss: 3.411, avg. samples / sec: 2148.37
Iteration:  11960, Loss function: 3.487, Average Loss: 3.408, avg. samples / sec: 2146.28
:::MLL 1586759532.851 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1586759532.851 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:  11980, Loss function: 3.260, Average Loss: 3.404, avg. samples / sec: 2144.78
Iteration:  12000, Loss function: 3.095, Average Loss: 3.402, avg. samples / sec: 2147.41
:::MLL 1586759539.556 eval_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 276}}
Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 10.25 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.50s)
DONE (t=0.50s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=2.32s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23323
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39780
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.24029
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06554
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24513
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38214
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32979
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10893
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37751
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53835
Current AP: 0.23323 AP goal: 0.23000
:::MLL 1586759552.683 eval_accuracy: {"value": 0.23323265818435723, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 389}}
:::MLL 1586759552.791 eval_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 392}}
:::MLL 1586759552.809 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1586759553.193 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-7,32-39', '--membind=0', '/opt/conda/bin/python3', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=8-15,40-47', '--membind=0', '/opt/conda/bin/python3', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=16-23,48-55', '--membind=1', '/opt/conda/bin/python3', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=24-31,56-63', '--membind=1', '/opt/conda/bin/python3', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-04-13 06:32:37 AM
RESULT,SINGLE_STAGE_DETECTOR,,2755,nvidia,2020-04-13 05:46:42 AM
