apiVersion: v1
kind: Pod
metadata:
  name: transformer
  namespace: nvidia
spec:
  restartPolicy: OnFailure
  containers:
    - name: transformer
      image: "quay.io/dfeddema/ngc_transformer_dgxsc16:latest"
      command: ["/bin/bash", "-ec", "cd /workspace/translation; export INSLURM=0; export NEXP=1;  export DATADIR=/var/home/core/data/u1/mlperf/dataset/mlperf_0.6_transformer_dataset; export LOGDIR=/data/mlperf/logs; printenv; source config_DGX1.sh; ./run_and_time.sh ; tail -f /dev/null " ]
      runAsUser: 1000
      env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: all
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"
        - name: NVIDIA_REQUIRE_CUDA
          value: "cuda>=5.0"
      securityContext:
        privileged: true
      resources:
        limits:
          nvidia.com/gpu: 4 # requesting 4 GPU
      volumeMounts:
      - mountPath: /data
        name: data-volume1
      - mountPath: /dev/shm
        name: dshm
  volumes:
  - name: data-volume1
    hostPath:
      # directory location on host
      path: /var/home/core/data/u1/mlperf/dataset/mlperf_0.6_transformer_dataset
  - name: dshm
    emptyDir:
      medium: Memory
